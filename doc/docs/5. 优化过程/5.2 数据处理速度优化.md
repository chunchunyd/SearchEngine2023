虽然我们使用的是静态的本地数据，但考虑到"搜索引擎"的普遍特征，对数据的更新应该是一项基本的要求。因此，我们对于数据的创建和更新也进行了一些优化。

1. **数据抓取和更新**：

   1. 在一开始，我们的数据抓取子系统中对数据库的Queryset使用的操作基本都是`create()`，但考虑到可能进行的更新，我们将其大量更改为`update_or_create()`，这极大的降低了我们数据读取的速度(本来读完所有数据用时约1.5小时，更改后要用接近5个小时)：

      > ![](.\pic\154539f60afffe37484adfed07f1d9c4_MD5.png)

   2. 统计了各种操作用时，我发现分词等其他操作的用时相较于数据库的IO操作几乎可以忽略不计，因此把重心放在了数据库操作的优化上。

   3. 参考了[优化sqlite3](/附/优化sqlite3/)之后，我总结了两个优化方向

      1. 通过**对事务的显示操作**，批量传入SQL操作语句，而不是默认的对于每次数据库操作都进行一次"开启事务-SQL操作-关闭事务"的流程；
      2. 尽可能多地使用**批量操作**，利用好SQL数据库本身对于批量操作的优化；

      反映到项目中的具体做法主要是

      3. 在部分SQL操作量较多的函数上添加`@transaction.atomic`，使得其中的SQL语句在函数执行完后统一开启事务传入数据库；
      4. 在一些循环中，将循环结果暂存入一个列表，循环一定轮次后手动开启事务并批量插入数据；
      5. 手动实现了一些filter操作，用HAVING替代WHERE，加速筛选速度。

      > 改前5000条用时：
      >
      > ```
      > 当前进度：999/68417，总用时：123.65395903587341秒
      > 当前进度：1999/68417，总用时：246.55316972732544秒
      > 当前进度：2999/68417，总用时：371.1040680408478秒
      > 当前进度：3999/68417，总用时：506.7788779735565秒
      > 当前进度：4999/68417，总用时：641.8681755065918秒
      > ```
      >
      > 改后10000条用时：
      >
      > ```
      > 当前进度：999/68417用时：34.04985427856445秒
      > 当前进度：1999/68417用时：72.40004515647888秒
      > 当前进度：2999/68417用时：118.16527771949768秒
      > 当前进度：3999/68417用时：170.25840783119202秒
      > 当前进度：4999/68417用时：221.5308060646057秒
      > 当前进度：5999/68417用时：277.9871973991394秒
      > 当前进度：6999/68417用时：339.6625759601593秒
      > 当前进度：7999/68417用时：404.6741075515747秒
      > 当前进度：8999/68417用时：472.87201833724976秒
      > 当前进度：9999/68417用时：543.7172710895538秒
      > ```
      >
      > 加速了三倍左右。

   4. 在数据库中为一些常用的筛选字段建立**索引**。

      > ![](.\pic\76d98faade2f6beb28b5a55cdddee671_MD5.png)

   最终用时仅有优化前的$\frac{1}{8}$左右。