对于从本地读取网页数据的爬虫,可以通过以下方式实现在前端显示爬取进度:

1. 在spider.py中编写爬虫逻辑时,获取总的网页数量total_count
2. 在pipelines.py中定义一个爬取进度的item_pipeline:

```python
class ProgressPipeline(object):
    total_count = 0  # 从spider中获取总数
    
    def open_spider(self, spider):
        self.current_count = 0
        self.total_count = spider.total_count  # 获取总数
        
    def process_item(self, item, spider):
        self.current_count += 1
        progress = self.current_count / self.total_count * 100
        print(f'Progress: {progress:.2f}%')
```

3. 在settings.py中启用该item_pipeline
4. 在spider.py的__init__方法中定义total_count,让ProgressPipeline获取

```python
class ExampleSpider(Spider):
    name = 'example'
    total_count = 1000   # 总网页数量
```

5. 在前端创建一个progress组件(比如progress bar),在其上请求定期刷新的API,该API读取日志中的进度打印信息,返回最新进度到前端。
6. 前端每秒(或500毫秒)请求一次该API,实时更新progress bar的进度,实现动态显示爬取进度。这种方式的工作流程是:
	1) 爬虫启动时,从spider类中获取总数量total_count
	2) item_pipeline在开启爬虫时获取总数,并定义当前进度current_count
	3) item_pipeline在处理每个item时增加当前进度,并打印日志
	4) 前端定期请求API,API读取最新日志获取当前进度
	5) 前端实时更新progress组件,显示最新进度

通过这种方式,我们可以让前端动态显示本地网页爬取的进度,这在一定程度上模拟了分布式爬虫的效果。